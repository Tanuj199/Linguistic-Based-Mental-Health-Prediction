# ğŸ§  Linguistic-Based Mental Health Risk Prediction

## ğŸ“Œ Project Overview
This project presents a machine learning solution to a critical social and public health problem: **the early identification of mental health risk in online text**.  

The model analyzes subtle **linguistic patterns** within self-reported text from a public dataset to predict a user's risk level.  
âš ï¸ **Note:** The goal is *not to diagnose*, but to provide a tool for early detection that can be integrated into online support systems.

---

## ğŸ“‚ Project Files and Structure
This project is structured into four sequential Python scripts and several data files.  
ğŸ‘‰ **You must run the scripts in order for the project to work correctly.**

- `1_data_preprocessing.py`  
  Handles data preparation:  
  - Loads raw text data  
  - Cleans text  
  - Tokenizes words â†’ numerical sequences  
  - Splits dataset into training, validation, testing  
  - Saves processed data + tokenizer  

- `2_model_training.py`  
  - Builds & trains a **Long Short-Term Memory (LSTM)** neural network  
  - Uses callbacks to save the best-performing model based on validation accuracy  

- `3_model_evaluation.py`  
  - Evaluates the trained model on test data  
  - Generates metrics: **accuracy, precision, recall**  

- `4_interactive_app.py`  
  - Final product using **Gradio**  
  - Provides an interactive web interface to type text & get **real-time risk prediction**  

### ğŸ“ Data Files
- `depression_dataset_reddit_cleaned.csv` â†’ Primary dataset  
- `processed_data.npz` â†’ Preprocessed train/val/test splits  
- `tokenizer.pkl` â†’ Saved Keras Tokenizer  
- `best_model.h5` â†’ Final trained model (weights + architecture)  

---

## ğŸš€ Getting Started
This project is designed to run in **Google Colab**.  

### Steps:
1. **Upload Dataset**  
   Upload `depression_dataset_reddit_cleaned.csv` into your Colab file browser.  

2. **Run Scripts Sequentially**  
   Create new code cells for each phase and run in order:  

---

## ğŸ“ Phase 1: Data Preprocessing (`1_data_preprocessing.py`)
- Cleans and preprocesses dataset  
- Tokenizes and pads sequences  
- Splits data into train/val/test  
- Saves processed data + tokenizer  

---

## ğŸ‹ï¸ Phase 2: Model Training (`2_model_training.py`)
- Builds **LSTM neural network**  
- Trains on processed data  
- Uses **EarlyStopping & ModelCheckpoint**  
- Saves best model â†’ `best_model.h5`  

---

## ğŸ“Š Phase 3: Model Evaluation (`3_model_evaluation.py`)
- Loads trained model + test data  
- Evaluates using:  
  - Accuracy  
  - Precision, Recall, F1-score  
  - Confusion Matrix (visualized with Seaborn)  

---

## ğŸ’» Phase 4: Interactive Application (`4_interactive_app.py`)
- Loads trained model & tokenizer  
- Uses **Gradio** to build an interactive web app  
- Input: user text  
- Output:  
  - Risk Level (**High Risk / Low Risk**)  
  - Message for user guidance  

---

## âš ï¸ Important Notes
- This tool is for **educational/research purposes only**  
- Not intended for medical diagnosis  
- Predictions indicate **risk patterns**, not clinical outcomes  

---

## ğŸ› ï¸ Tech Stack
- **Python**  
- **TensorFlow / Keras** (LSTM model)  
- **scikit-learn** (evaluation)  
- **Gradio** (web interface)  
- **pandas, numpy, seaborn, matplotlib**  

---

## âœ… Example Workflow
1. Upload dataset â†’ `depression_dataset_reddit_cleaned.csv`  
2. Run `1_data_preprocessing.py` â†’ saves `processed_data.npz` & `tokenizer.pkl`  
3. Run `2_model_training.py` â†’ trains & saves `best_model.h5`  
4. Run `3_model_evaluation.py` â†’ check performance metrics  
5. Run `4_interactive_app.py` â†’ launch Gradio app for predictions  

---

## ğŸ“Œ Final Thoughts
This project demonstrates how **linguistic analysis with machine learning** can aid in **early detection of mental health risks**.  
With further development, it could be integrated into **online support platforms** for real-world impact.  

---
